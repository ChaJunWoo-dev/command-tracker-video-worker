## 📌 프로젝트 소개

커맨드 트래커는 1대1 격투 게임 '스트리트파이터6' 영상에서 플레이어의 커맨드 입력을 자막화해주는 서비스입니다.

커맨드 시스템에 익숙치 않은 초보자는 영상을 보며 일일이 입력을 추정해야 하며, 이는 높은 진입장벽이 됩니다.

이 서비스는 AI 기반 관절 추출 모델과 후처리 알고리즘을 활용하여 플레이어의 동작을 분석하고, 이를 커맨드로 변환한 뒤 영상에 표시합니다.

덕분에 초보자도 원하는 캐릭터의 커맨드를 손쉽게 확인할 수 있습니다.


## 🔗 링크  

<div align="center">
  
[시연 영상](https://drive.google.com/file/d/1bkSmT2jVh1yR19HSS-pmg3K0qPOkGw3N/view?usp=sharing) | [클라이언트 레포지토리](https://github.com/ChaJunWoo-dev/command-tracker-frontend) | [API 서버 레포지토리](https://github.com/ChaJunWoo-dev/command-tracker-backend)

</div>


## ⚙️ 레포지토리 구성 및 역할

### 클라이언트 레포지토리
- 사용자가 분석할 영상을 업로드하고 컷 편집할 수 있는 웹 UI를 제공합니다.
- 분석할 캐릭터 위치, 캐릭터 선택, 이메일 입력 폼을 제공합니다.
- 주요 기능
  - 영상 업로드 및 편집 UI
  - 캐릭터 위치, 캐릭터 선택, 이메일 입력 폼
  - API 서버로 영상 전송

### API 서버 레포지토리
- JWT 토큰을 검증한 후 사용자의 S3 영상 업로드 요청을 처리하고, 메시지 큐를 통해 워커 서버로 작업을 전달합니다.
- 최종 결과물의 접근 URL을 발급하여 이메일로 전송합니다.
- 클라이언트와 워커 서버 간의 중계 역할을 수행하여 유지보수성과 안정성을 높입니다.
- 주요 기능
  - 사용자 입력 값 검증 및 JWT 토큰 발급
  - JWT 토큰 검증 후 S3 영상 업로드 처리
  - 메시지 큐를 통해 워커 서버에 작업 요청 발행
  - 결과물 presigned URL 발급 및 이메일 전송
 
### 워커 서버 레포지토리
- 메시지 큐로부터 수신한 작업 요청을 기반으로, 영상 컷 편집과 AI 기반 커맨드 분석을 수행하는 Python 서버입니다.
- 주요 기능
  - FFmpeg를 이용한 영상 컷 편집  
  - AI 모델을 활용한 플레이어 동작 분석 및 커맨드 추정
  - 멀티 스레딩을 통한 AI 분석 병렬 처리
  - 추정 결과를 이미지 오버레이로 영상에 삽입 후 S3업로드

## 📑 목차

- [🛠 기술 스택](#-기술-스택)  
    - [클라이언트](#클라이언트)  
    - [RabbitMQ 도입 배경](#rabbitmq-도입-배경)
    - [Express 도입 배경](#express-도입-배경)  
- [🧠 기술적 챌린지](#-기술적-챌린지)  
    - [비동기 이벤트 루프 블로킹 방지](#비동기-이벤트-루프-블로킹-방지)  
    - [AI로 커맨드 추정하기](#ai로-커맨드-추정하기)
    - [영상 편집 스트림 처리 문제](#영상-편집-스트림-처리-문제)   
- [🔍 작업 방식](#-작업-방식)  
    - [깃 브랜치 전략](#깃-브랜치-전략)  
    - [PR 규칙](#pr-규칙)  
    - [협업 시 신경 썼던 부분](#협업-시-신경-썼던-부분)  
- [📆 일정 및 팀원](#-일정-및-팀원)  
- [💭 개인 회고](#-개인-회고)  
    - [아쉬운 점](#아쉬운-점)  
    - [향후 개선 방향](#향후-개선-방향)  


## **🛠** 기술 스택

### 클라이언트

<span>
  <img src="https://img.shields.io/badge/javascript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black">
  <img src="https://img.shields.io/badge/react-61DAFB?style=for-the-badge&logo=react&logoColor=black">
  <img src="https://img.shields.io/badge/vite-646CFF?style=for-the-badge&logo=vite&logoColor=white">
  <img src="https://img.shields.io/badge/zustand-000000?style=for-the-badge&logo=zustand&logoColor=white">
  <img src="https://img.shields.io/badge/tailwindcss-06B6D4?style=for-the-badge&logo=tailwindcss&logoColor=white">
</span>

### API 서버

<span>
  <img src="https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white">
  <img src="https://img.shields.io/badge/Express-000000?style=for-the-badge&logo=express&logoColor=white">
  <img src="https://img.shields.io/badge/RabbitMQ-FF6600?style=for-the-badge&logo=rabbitmq&logoColor=white">
</span>

### 워커 서버

<span>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white">
  <img src="https://img.shields.io/badge/FFmpeg-007808?style=for-the-badge&logo=ffmpeg&logoColor=white">
  <img src="https://img.shields.io/badge/RabbitMQ-FF6600?style=for-the-badge&logo=rabbitmq&logoColor=white">
</span>

### 배포

<span>
  <img src="https://img.shields.io/badge/vercel-E34F26?style=for-the-badge&logo=vercel&logoColor=black">
  <img src="https://img.shields.io/badge/amazonaws-232F3E?style=for-the-badge&logo=amazonaws&logoColor=black">
  <img src="https://img.shields.io/badge/CloudAMQP-FF6600?style=for-the-badge&logo=rabbitmq&logoColor=white">
</span>

### RabbitMQ 도입 배경

영상 분석 및 커맨드 추정 작업은 연산 비용이 높고 처리 시간이 긴 작업입니다. 이를 HTTP 요청–응답 구조로 처리할 경우, 요청 대기 시간이 길어질 뿐만 아니라 웹 서버와 AI 서버 모두의 안정성에 부정적인 영향을 줄 수 있습니다.

이에 따라 영상 분석 작업을 메시지 큐 기반으로 분리하여 비동기 처리 구조로 전환했습니다. 웹/API 서버는 작업 요청만 큐에 발행하고 즉시 응답하며, 워커 서버는 큐를 소비하여 독립적으로 연산을 수행합니다. 이를 통해 서버 간 결합도를 낮추고 안정적인 처리가 가능합니다.

또한 AI 워커 서버는 메시지 큐 소비와 결과 처리만 담당하므로, 웹 프레임워크 없이 동작할 수 있습니다. 그 결과 HTTP 라우팅이나 요청 처리 오버헤드를 제거하고, 영상 편집이나 분석과 같은 핵심 연산 로직에만 집중할 수 있도록 구성했습니다.

### Express 도입 배경

프론트엔드가 React 기반으로 구성되어 있고, 동일한 JavaScript 생태계인 Express를 API 서버로 채택함으로써 개발 생산성을 높일 수 있었습니다.

또한 Express의 미들웨어 구조를 활용해 사용자 입력 값 검증과 JWT 토큰 검증을 요청 초기에 처리함으로써, 유효하지 않은 요청에 대한 불필요한 S3 업로드 및 후속 작업을 사전에 차단했습니다. 이를 통해 서버 부하를 줄이고 전체 응답 속도를 개선했습니다.

## 🧠 기술적 챌린지

### 요약

- 동기 AI 추론으로 인한 이벤트 루프 블로킹 문제를 해결하기 위해 ThreadPoolExecutor 기반 멀티 스레드 구조 도입
- 객체 탐지 실패로 인한 포즈 추정 불안정 문제를, 연속 프레임 분석이 아닌 단일 의미 프레임 기반 커맨드 추정 방식으로 해결
- MP4 스트림 입력이 FFmpeg에서 처리되지 않는 문제를 tempfile 기반 임시 디렉터리 구조로 변경하여 안정성 확보

---

### 비동기 이벤트 루프 블로킹 방지

#### 원인 분석
워커 서버는 RabbitMQ로부터 메시지를 수신한 뒤, 영상 컷 편집과 AI기반 커맨드 추정을 수행하는 구조입니다.
이 과정에서 객체 감지 AI모델 및 포즈 추정 AI모델 같은 로직은 동기로 동작하고, 이로 인해 이벤트 루프에서 블로킹되는 문제가 발생했습니다.

즉, 한 번에 하나의 요청밖에 처리하지 못하는 상황이었습니다. 

#### 해결 방법
AI 분석 로직은 대부분 CUDA 기반 GPU 연산으로 수행됩니다. (CPU도 가능하나 분석 시간이 수십배 차이가 납니다.)
이러한 GPU 작업은 Python GIL(Global Interpreter Lock)의 영향을 거의 받지 않기 때문에, 멀티 스레드 환경에서도 병렬 처리가 가능합니다.

이에 따라 멀티 스레드 도입을 고려했습니다. 멀티 스레드를 도입하면 AI분석을 병렬로 처리할 수 있을 뿐만 아니라 기존에 로드된 모델 인스턴스를 재사용 할 수 있어 효율도 높입니다.
이러한 이유로, 이벤트 루프 블로킹을 방지하면서도 성능과 리소스 효율을 동시에 만족하는 `ThreadPoolExecutor` 기반 구조를 최종 선택했습니다.

> 멀티 프로세스는 작업마다 별도의 프로세스를 생성해야 하며, 각 프로세스가 AI 모델을 개별적으로 로드하게 되어 비효율적이라 판단했습니다.

#### multi-threading과 ThreadPoolExecutor

1. asyncio와의 통합

    이 프로젝트는 `aio-pika`나 `aioboto3`처럼 `asyncio`구조로 구성되어 있어, 동기 함수가 이벤트 루프를 블로킹하지 않도록 하는 것이 필수적입니다.
    
    `loop.run_in_executor()`는 `ThreadPoolExecutor`를 직접 지원하므로, 동기 함수 호출을 비동기 흐름에 자연스럽게 연결할 수 있습니다. 실행 결과는 `Future`로 관리되어 `await` 구문을 통해 안전하게 처리되며, 예외 역시 이벤트 루프 컨텍스트에서 일관되게 전달됩니다.
   
    반면 `threading.Thread`를 사용할 경우, 작업 완료 신호 전달과 예외 처리를 위해 `Future` 래핑과 콜백을 직접 구현해야 하므로 코드 복잡도가 크게 증가하게 됩니다.


2. 스레드 생명주기 관리 편의성
   
    일반 `Thread`는 작업마다 새 스레드 생성/삭제가 일어나므로 오버헤드가 발생하며, 이는 반복 요청 처리하는 환경에서 매우 비효율적입니다.

    `ThreadPoolExcutor`는 미리 생성해둔 스레드 풀을 사용하여, 스레드를 재사용하고 안정성도 높입니다.


3. 동시 실행 수 제한

    AI 추론 및 영상 분석 작업은 GPU 자원을 집중적으로 사용합니다. 동시 실행 수를 제한하지 않으면 GPU 메모리 경쟁이나 연산 지연이 발생할 수 있어, 안정적인 서비스 운영이 어렵습니다.
   
    `ThreadPoolExecutor`는 `max_workers` 옵션을 통해 동시 실행 수를 명확하게 제한할 수 있어, GPU 리소스 사용량을 예측 가능하게 관리할 수 있습니다. 반면 일반적인 Thread 기반 구현에서는 세마포어, 락 등의 동기화 수단을 별도로 구현해야 하며, 이는 코드 복잡성과 오류 가능성을 함께 증가시킵니다.

#### 개선 계획  
- 영상 길이 기반 동적 타임아웃 도입

    현재 워커 서버는 타임아웃이 없습니다. 만약 오류로 인해 특정 스레드를 한 작업이 계속 점유하는 문제를 방지하기 위해 작업 타임아웃을 설정하여 자원 고갈 방지와 처리 안정성을 높일 계획입니다.
  
---

### AI로 커맨드 추정하기

#### 커맨드 추정 방법 선정
게임 영상에서 캐릭터의 커맨드를 추정하는 방법에는 크게 이미지 유사도 기반 방식과 AI 기반 분석 방식이 있습니다.
이미지 유사도 방식은 특정 프레임의 이미지를 미리 정의된 템플릿과 비교하는 구조로, 구현 난이도는 낮지만 캐릭터 외형 변경, 연출 효과 등에 매우 취약하다는 한계가 있습니다.

따라서 이 프로젝트에서는 캐릭터의 동작을 수치화하여 해석할 수 있는 AI 기반 포즈 추정 방식을 선택했습니다.
특정 프레임에서 추출한 2D 관절 좌표를 기반으로 관절 각도를 계산하고, 각도 조합이 사전에 정의된 조건을 만족하는지를 기준으로 커맨드를 추정하는 구조입니다.
이 방식은 시각적 외형 변화에 영향을 받지 않고, 규칙 기반으로 동작을 정의할 수 있다는 장점이 있습니다.

#### 직면했던 어려움
포즈 추정을 수행하기 위해서는 선행 단계로 객체 탐지(detection)가 반드시 필요했습니다.
게임 캐릭터는 사람의 형태를 띠고 있어 기본적으로 person detection 방식을 사용했지만, 실제 플레이 영상에서는 스킬 이펙트, 타격 효과, 화면 흔들림, 사람과는 괴리감 있는 과장된 동작 등으로 인해 일부 프레임에서 캐릭터가 탐지되지 않는 문제가 빈번하게 발생했습니다.

객체가 탐지되지 않은 프레임에서는 포즈 추정을 수행할 수 없었고, 그 결과 관절 좌표를 연속적으로 얻지 못했습니다. 
이로 인해 관절 좌표의 연속적인 변화를 기반으로 커맨드를 판별하는 방식은 커맨드를 추정하기가 어렵다고 판단했습니다.

#### 해결 방법
이 문제를 해결하기 위해, AI가 사람으로 인식하기 쉬운 특정 단일 프레임에 집중하는 구조로 설계를 변경했습니다.

게임 내 대부분의 기술은 이펙트가 발생하기 이전에, 비교적 자연스러운 사전 동작(예: 준비 자세, 팔을 드는 구간 등)을 포함하고 있습니다.
이 구간은 스킬 이펙트가 적고, 사람 형태와의 괴리도 작아 객체 탐지 및 포즈 추정이 상대적으로 안정적으로 수행됩니다.

따라서 해당 사전 동작 프레임에서 추출한 2D 관절 좌표를 기준으로,
어깨–팔꿈치–손목 등 주요 관절 간 각도를 계산하고,
이 각도들이 미리 정의된 조건을 만족하는지를 판단하여 커맨드를 추정하는 방식으로 전환했습니다.

이 접근 방식은 일부 프레임에서 탐지가 실패하더라도, 의미 있는 프레임만 선택적으로 활용하기 때문에 전체 파이프라인의 안정성을 크게 개선할 수 있었습니다.

#### 개선 계획
위치 기반 판별 구조상, 영상 도중 두 캐릭터의 위치가 바뀌는 경우 대상 캐릭터가 바뀌는 한계가 존재합니다.

우선 가장 단순한 방식으로는 x좌표 교차 감지가 있습니다.
두 캐릭터의 박스의 중심 x 좌표가 매우 가까워지거나 교차되는 시점을 기준으로 좌측/우측 캐릭터를 스왑하는 방식입니다. 
하지만 이 방식은 격투 게임 특성 상 근접전이 잦아 의도치 않은 교차가 자주 발생할 수 있습니다.

다음은 프레임 간 위치 연속성을 이용한 트래킹 방식 AI 적용입니다.
이 방식은 이전 프레임의 위치와 속도를 기반으로 동일 객체를 추적하지만, 스킬 이펙트나 탐지 실패가 발생하는 프레임이 끼어들면 ID가 쉽게 끊어지는 문제가 있었습니다.
직접 테스트 해본 결과 트래킹 안정성이 낮아 실사용은 어렵다고 판단했습니다.

결과적으로 위치 변경 문제를 해결하기엔 두 방식 모두 안정성이 떨어지고, 오판 시 오히려 잘못된 분석 결과를 가져올 위험이 있었습니다. 
이에 따라 현재는 사용자 입력 기반 좌측/우측 선택 방식을 유지하고, 향후 AI모델 안정성이 개선되었을 때 자동 추적 방식 도입을 재검토할 계획입니다.

---

### 영상 편집 스트림 처리 문제

#### 원인 분석
워커 서버는 S3에 저장된 원본 영상을 다운로드한 뒤 FFmpeg를 이용해 컷 편집과 오버레이 처리를 수행합니다.
초기 설계에서는 S3에서 다운로드한 영상을 메모리 스트림 형태로 FFmpeg에 직접 전달하여 디스크 I/O를 줄이고 처리 속도를 높이려 했습니다.

그러나 이 방식은 MP4 포맷의 구조적 특성과 충돌했습니다.
MP4 컨테이너는 파일의 끝부분에 위치한 moov atom(메타데이터 및 프레임 인덱스)을 기준으로 디코딩이 이루어지는데,
파이프나 네트워크 스트림과 같은 non-seekable 입력 환경에서는 FFmpeg가 해당 정보를 읽을 수 없어 정상적인 처리가 불가능했습니다.

#### 시도와 한계: 스트림 친화 포맷(WebM/MKV)으로 변환 후 업로드
API 서버에서 원본 영상 업로드를 하는 단계에서 스트리밍에 적합한 포맷으로 변환하는 방안도 검토했습니다. 이 방식은 충분히 사용 가능하나, 
이를 위해 API 서버에 FFmpeg 처리를 추가해야 했고, 요청-응답 경로가 길어지면서 클라이언트 응답 지연이 발생해 사용자 경험을 떨어트렸습니다.
또한 전체 인프라 구조가 불필요하게 복잡해지는 문제가 있었습니다.

#### 해결 방법: 임시 디렉토리 생성 후 작업 완료 후 파일 정리
최종적으로 임시 디렉터리에 영상을 로컬 파일로 저장한 뒤 FFmpeg 처리를 수행하는 방식을 채택했습니다.
파이썬의 `tempfile`라이브러리를 사용하여 임시 디렉토리를 생성하고 자동으로 정리되도록 구성해, 디스크 사용 문제를 최소화했습니다.

이 구조를 통해 MP4 스트림 처리의 근본적인 제약을 우회하면서도,
기존 API 서버 구조를 변경하지 않고 워커 서버 내부에서 안정적으로 영상 편집을 수행할 수 있었습니다.
결과적으로 안정성과 구현 복잡도 사이에서 가장 현실적인 선택이었습니다.

## 🔍 **작업 방식**

### 깃 브랜치 전략
    
Github Flow 전략을 채택했습니다. Git Flow는 develop, release, hotfix 등 브랜치가 많아서 관리가 복잡하고 작은 팀에서는 오히려 비효율적이라 생각했습니다. 반면 Github Flow는 main 브랜치를 기준으로 병합하기 때문에 빠른 개발 사이클을 가져갈 수 있어 개발 기간을 확보할 수 있다고 생각하여 적합하다고 판단했습니다. 
    
### PR 규칙
    
PR 작성 시 이슈 번호를 반드시 포함하고 템플릿을 지켜 작성하였습니다. 내용에는 변경된 내용과 코드 리뷰어가 확인해야 할 부분을 간단히 명시하였습니다. 또한 팀원의 승인이 반드시 있어야 병합할 수 있도록 하여 실수로 인한 병합을 예방하였습니다.
    
### 협업 시 신경 썼던 부분
  
의견 충돌이 발생할 수 있는 상황에서도 감정적인 표현을 배제하고, 사실과 근거 중심으로 의사소통했습니다.

예를 들어 관절 좌표 데이터를 커맨드로 변환하는 방식에 대해, 좌·우 캐릭터 위치를 기준으로 규칙 기반으로 처리할지, AI 기반 트래커를 사용할지에 대해 팀 내에서 의견이 나뉜 적이 있습니다.

이 과정에서 각자가 제안한 방식을 직접 구현 및 테스트한 뒤, 결과를 비교·검증하는 방식으로 추가 논의를 진행했고, 성능과 안정성 측면에서 더 적합한 방안을 최종적으로 채택했습니다.
    

## 📆 일정 및 팀원

진행 기간 : 5주

팀원 : 차준우, 조성경 (총 2명)

- 1주차
    - 아이디어 선정
    - POC 진행 - 캐릭터의 커맨드를 추정하기 위한 관절 데이터 추출 성능 확인
- 2주차
    - POC 진행 - 캐릭터의 커맨드를 추정하기 위한 관절 데이터 추출 성능 확인
    - 칸반 작성
    - 기술 스택 조사
- 3주차
    - 프로젝트 환경 세팅
    - 공통 컴포넌트 구현
    - 영상 편집 구현
    - 영상 업로드 구현
    - 결과물 확인 링크 메일 전송 구현
- 4주차
    - 영상 분석하여 관절 데이터 추출 구현
    - Re-ID 성능 테스트
    - 동작 학습 데이터 수집 및 AI 기반 커맨드 추출 테스트
    - 관절 데이터 기반 커맨드 추출 구현
- 5주차
    - 배포


## 💭 개인 회고

이번 프로젝트를 통해 단순히 기능을 구현하는 것을 넘어, 실제 사용자가 어떤 문제를 겪고 있는지를 정의하고, 그에 맞는 해결책을 설계하는 것이 얼마나 중요한지 체감했습니다. 또한, AI 기반 관절 추정을 처음에는 캐릭터별 학습 방식으로 구현했으나, 매번 라벨링·학습을 반복해야 해 유지보수 한계가 컸습니다. 이를 좌/우 캐릭터 구분 방식으로 전환하며, 기술적 완벽함보다 현실적 확장성을 우선하는 선택이 더 효율적일 수 있음을 배웠습니다.

### 아쉬운 점

AI 기반 커맨드 추정의 정확도에 대한 확신이 부족해, 필요한 수준보다 지나치게 완벽한 결과를 목표로 POC에 과도한 시간을 투입했습니다. 이로 인해 POC 단계에서 모델 구조, 조건식, 예외 케이스 보정에 과도한 시간을 투입하게 되었고, 결과적으로 전체 시스템 설계와 개발 일정이 지연되었습니다.

사용자 경험 개선 고려나 코드 구조 정리, 인프라 단순화같은 제품 완성도를 높이는 작업에 충분한 시간을 들이지 못한 점이 아쉬움으로 남습니다. 
앞으로는 목표 수준을 현실적으로 설정하여 기술적 완성도와 개발 속도 사이의 균형을 보다 전략적으로 관리할 계획입니다.

### 향후 개선 방향

- 캐릭터별 커맨드 추가 매핑

### 사용한 AI모델 다운로드 링크
[객체 탐지 - RTM Detector](https://drive.google.com/file/d/1oGTQijt1DnUnddS7PD_sGAgT4lxiX2wQ/view?usp=sharing)
[포즈 추정 - RTM Pose](https://drive.google.com/file/d/1E3T_cVGcfFSKp3AErKeqTAbjOhebDJxO/view?usp=sharing)
